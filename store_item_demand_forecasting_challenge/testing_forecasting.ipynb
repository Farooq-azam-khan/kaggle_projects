{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import model_selection\n",
    "from sklearn import (svm, \n",
    "                     neighbors, \n",
    "                     ensemble, \n",
    "                    linear_model, \n",
    "                    naive_bayes, \n",
    "                    tree, \n",
    "                    discriminant_analysis)\n",
    "\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline \n",
    "\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.read_csv('./data/train.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         date  store  item  sales\n",
      "0  2013-01-01      1     1     13\n",
      "1  2013-01-02      1     1     11\n",
      "2  2013-01-03      1     1     14\n",
      "3  2013-01-04      1     1     13\n",
      "4  2013-01-05      1     1     10\n"
     ]
    }
   ],
   "source": [
    "print(train_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = train_data.copy(deep=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Datetime_date'] = data['date'].map(lambda x: datetime.datetime.strptime(x, '%Y-%m-%d'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['year'] = data['Datetime_date'].map(lambda x: x.year)\n",
    "data['month'] = data['Datetime_date'].map(lambda x: x.month)\n",
    "data['day'] = data['Datetime_date'].map(lambda x: x.day)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   year  month  day\n",
      "0  2013      1    1\n",
      "1  2013      1    2\n",
      "2  2013      1    3\n",
      "3  2013      1    4\n",
      "4  2013      1    5\n"
     ]
    }
   ],
   "source": [
    "date_cols = ['year', 'month', 'day']\n",
    "print(data[date_cols].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n"
     ]
    }
   ],
   "source": [
    "print(data['store'].unique().tolist())\n",
    "# there are 10 stores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50]\n"
     ]
    }
   ],
   "source": [
    "print(data['item'].unique().tolist())\n",
    "# there are 50 items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[13, 11, 14, 10, 12, 9, 7, 5, 16, 18, 15, 8, 6, 21, 20, 17, 22, 19, 24, 23, 26, 25, 27, 38, 34, 29, 31, 30, 4, 36, 28, 33, 32, 37, 35, 43, 40, 41, 39, 42, 50, 45, 44, 47, 53, 49, 46, 48, 51, 58, 54, 57, 55, 52, 3, 2, 1, 59, 56, 60, 63, 69, 64, 67, 65, 71, 61, 73, 62, 82, 78, 68, 74, 70, 87, 66, 77, 88, 76, 75, 102, 72, 92, 86, 79, 85, 81, 90, 84, 80, 103, 97, 96, 95, 89, 104, 94, 100, 91, 83, 106, 101, 98, 115, 93, 111, 119, 99, 108, 110, 120, 105, 126, 109, 114, 113, 112, 121, 107, 117, 118, 139, 124, 131, 123, 138, 134, 127, 136, 116, 125, 122, 128, 150, 129, 135, 137, 132, 133, 145, 130, 144, 0, 148, 141, 140, 152, 147, 169, 156, 159, 153, 142, 157, 155, 163, 143, 154, 165, 146, 160, 158, 151, 164, 171, 161, 177, 162, 175, 181, 168, 167, 149, 174, 170, 176, 178, 166, 173, 187, 182, 189, 179, 172, 204, 180, 190, 191, 210, 184, 183, 186, 185, 199, 196, 194, 197, 207, 209, 195, 198, 231, 205, 192, 200, 193, 188, 208, 201, 214, 206, 203, 202]\n"
     ]
    }
   ],
   "source": [
    "print(data['sales'].unique().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('./data/train_features.csv.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline Model: 0.004694835680751174\n"
     ]
    }
   ],
   "source": [
    "print(\"Baseline Model:\", 1 / len(data['sales'].unique().tolist()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = ['sales']\n",
    "features = ['year', 'month', 'day', 'store', 'item']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_data = data.sample(20000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = model_selection.train_test_split(small_data[features], small_data[target], random_state=0)\n",
    "train_y = train_y['sales']\n",
    "test_y = test_y['sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLA = [\n",
    "    # ensemble\n",
    "    ensemble.AdaBoostClassifier(),\n",
    "    ensemble.AdaBoostRegressor(),\n",
    "    ensemble.RandomForestClassifier(), \n",
    "    ensemble.RandomForestRegressor(),\n",
    "    ensemble.BaggingClassifier(),\n",
    "    ensemble.GradientBoostingRegressor(),\n",
    "    ensemble.ExtraTreesRegressor(),\n",
    "    \n",
    "    #Nearest Neighbor\n",
    "    neighbors.KNeighborsClassifier(),\n",
    "    \n",
    "    # svm\n",
    "    svm.LinearSVR(), \n",
    "    svm.SVR(), \n",
    "    svm.NuSVR(),\n",
    "    \n",
    "    \n",
    "    # tree\n",
    "    tree.DecisionTreeClassifier(),\n",
    "    tree.DecisionTreeRegressor(),    \n",
    "]\n",
    "MLA_Compare = pd.DataFrame(columns=['Name', 'Train_Score', 'Test_Score', 'Time', 'Parameters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting: AdaBoostClassifier\n",
      "starting: AdaBoostRegressor\n",
      "starting: RandomForestClassifier\n",
      "starting: RandomForestRegressor\n",
      "starting: BaggingClassifier\n",
      "starting: GradientBoostingRegressor\n",
      "starting: ExtraTreesRegressor\n",
      "starting: KNeighborsClassifier\n",
      "starting: LinearSVR\n",
      "starting: SVR\n",
      "starting: NuSVR\n",
      "starting: DecisionTreeClassifier\n",
      "starting: DecisionTreeRegressor\n"
     ]
    }
   ],
   "source": [
    "row_number = 0\n",
    "for alg in MLA:\n",
    "    alg_name = alg.__class__.__name__\n",
    "    print(\"starting:\", alg_name)\n",
    "    start = time.time()\n",
    "    alg.fit(train_X, train_y)\n",
    "    end = time.time()\n",
    "    time_taken = end - start \n",
    "    train_score = alg.score(train_X, train_y)\n",
    "    test_score = alg.score(test_X, test_y)\n",
    "    \n",
    "    # add to pandas dataframe\n",
    "    MLA_Compare.loc[row_number] = [alg_name, train_score, test_score, time_taken, alg.get_params()]\n",
    "    row_number+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Train_Score</th>\n",
       "      <th>Test_Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Parameters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RandomForestRegressor</td>\n",
       "      <td>0.964214</td>\n",
       "      <td>0.799507</td>\n",
       "      <td>0.395792</td>\n",
       "      <td>{'bootstrap': True, 'criterion': 'mse', 'max_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>GradientBoostingRegressor</td>\n",
       "      <td>0.698639</td>\n",
       "      <td>0.692527</td>\n",
       "      <td>0.524206</td>\n",
       "      <td>{'alpha': 0.9, 'criterion': 'friedman_mse', 'i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.677648</td>\n",
       "      <td>0.060964</td>\n",
       "      <td>{'criterion': 'mse', 'max_depth': None, 'max_f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ExtraTreesRegressor</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.569124</td>\n",
       "      <td>0.304945</td>\n",
       "      <td>{'bootstrap': False, 'criterion': 'mse', 'max_...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AdaBoostRegressor</td>\n",
       "      <td>0.238471</td>\n",
       "      <td>0.233457</td>\n",
       "      <td>0.300813</td>\n",
       "      <td>{'base_estimator': None, 'learning_rate': 1.0,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NuSVR</td>\n",
       "      <td>0.120764</td>\n",
       "      <td>0.085279</td>\n",
       "      <td>20.237430</td>\n",
       "      <td>{'C': 1.0, 'cache_size': 200, 'coef0': 0.0, 'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SVR</td>\n",
       "      <td>0.122374</td>\n",
       "      <td>0.081321</td>\n",
       "      <td>16.462116</td>\n",
       "      <td>{'C': 1.0, 'cache_size': 200, 'coef0': 0.0, 'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BaggingClassifier</td>\n",
       "      <td>0.984667</td>\n",
       "      <td>0.027800</td>\n",
       "      <td>1.418187</td>\n",
       "      <td>{'base_estimator': None, 'bootstrap': True, 'b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.989333</td>\n",
       "      <td>0.026600</td>\n",
       "      <td>1.043404</td>\n",
       "      <td>{'bootstrap': True, 'class_weight': None, 'cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>DecisionTreeClassifier</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.024400</td>\n",
       "      <td>0.277840</td>\n",
       "      <td>{'class_weight': None, 'criterion': 'gini', 'm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.216133</td>\n",
       "      <td>0.020400</td>\n",
       "      <td>0.017047</td>\n",
       "      <td>{'algorithm': 'auto', 'leaf_size': 30, 'metric...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>0.020133</td>\n",
       "      <td>0.018800</td>\n",
       "      <td>5.993759</td>\n",
       "      <td>{'algorithm': 'SAMME.R', 'base_estimator': Non...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LinearSVR</td>\n",
       "      <td>-0.031629</td>\n",
       "      <td>-0.027311</td>\n",
       "      <td>1.629060</td>\n",
       "      <td>{'C': 1.0, 'dual': True, 'epsilon': 0.0, 'fit_...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Name  Train_Score  Test_Score       Time  \\\n",
       "3       RandomForestRegressor     0.964214    0.799507   0.395792   \n",
       "5   GradientBoostingRegressor     0.698639    0.692527   0.524206   \n",
       "12      DecisionTreeRegressor     1.000000    0.677648   0.060964   \n",
       "6         ExtraTreesRegressor     1.000000    0.569124   0.304945   \n",
       "1           AdaBoostRegressor     0.238471    0.233457   0.300813   \n",
       "10                      NuSVR     0.120764    0.085279  20.237430   \n",
       "9                         SVR     0.122374    0.081321  16.462116   \n",
       "4           BaggingClassifier     0.984667    0.027800   1.418187   \n",
       "2      RandomForestClassifier     0.989333    0.026600   1.043404   \n",
       "11     DecisionTreeClassifier     1.000000    0.024400   0.277840   \n",
       "7        KNeighborsClassifier     0.216133    0.020400   0.017047   \n",
       "0          AdaBoostClassifier     0.020133    0.018800   5.993759   \n",
       "8                   LinearSVR    -0.031629   -0.027311   1.629060   \n",
       "\n",
       "                                           Parameters  \n",
       "3   {'bootstrap': True, 'criterion': 'mse', 'max_d...  \n",
       "5   {'alpha': 0.9, 'criterion': 'friedman_mse', 'i...  \n",
       "12  {'criterion': 'mse', 'max_depth': None, 'max_f...  \n",
       "6   {'bootstrap': False, 'criterion': 'mse', 'max_...  \n",
       "1   {'base_estimator': None, 'learning_rate': 1.0,...  \n",
       "10  {'C': 1.0, 'cache_size': 200, 'coef0': 0.0, 'd...  \n",
       "9   {'C': 1.0, 'cache_size': 200, 'coef0': 0.0, 'd...  \n",
       "4   {'base_estimator': None, 'bootstrap': True, 'b...  \n",
       "2   {'bootstrap': True, 'class_weight': None, 'cri...  \n",
       "11  {'class_weight': None, 'criterion': 'gini', 'm...  \n",
       "7   {'algorithm': 'auto', 'leaf_size': 30, 'metric...  \n",
       "0   {'algorithm': 'SAMME.R', 'base_estimator': Non...  \n",
       "8   {'C': 1.0, 'dual': True, 'epsilon': 0.0, 'fit_...  "
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MLA_Compare.sort_values(by=['Test_Score'], ascending=False, inplace=True)\n",
    "MLA_Compare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLA_Compare.to_csv('./scores/mla_algorithms_trainning_20k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {\n",
    "    'loss':['ls','lad','huber', 'quantile'],\n",
    "    'learning_rate':[0.1, 0.01, 0.001], \n",
    "    'n_estimators':[100,200,300],\n",
    "    'max_depth':[1,2,3,4],\n",
    "    'min_samples_split':[0.1, 0.25, 0.75, 1.0], #(0, 1)\n",
    "    'min_weight_fraction_leaf':[0,0.25,0.5],  # [0, 0.5]  \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tune_model = model_selection.GridSearchCV(ensemble.GradientBoostingRegressor(), param_grid=param_grid)\n",
    "tune_model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8338084879771797\n",
      "0.8231509811658636\n"
     ]
    }
   ],
   "source": [
    "print(tune_model.score(train_X, train_y))\n",
    "print(tune_model.score(test_X, test_y))\n",
    "print(tune_model.score(data[features], data[target]['sales']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "gird_params = [\n",
    "#     AdaBoostClassifier\n",
    "    {\n",
    "        'n_estimators':[30, 35, 40, 35, 50, 55, 60], \n",
    "        'learning_rate': [0.1, 0.01, 0.001], \n",
    "    }, \n",
    "#     AdaBoostRegressor\n",
    "    {\n",
    "        'n_estimators':[30, 35, 40, 35, 50, 55, 60], \n",
    "        'learning_rate':[0.1, 0.01, 0.001],   \n",
    "        'loss':['linear', 'square', 'exponential']\n",
    "    },\n",
    "#     RandomForestClassifier\n",
    "    {\n",
    "        'n_estimators':[1, 5, 10, 15, 20, 25],\n",
    "        'criterion':['gini', 'entropy']\n",
    "    },\n",
    "#     RandomForestRegressor\n",
    "    {\n",
    "        'n_estimators':[30, 35, 40, 45, 50, 55, 60], \n",
    "        'criterion':['mse', 'mae'],\n",
    "    },\n",
    "#     BaggingClassifier\n",
    "    {\n",
    "        'n_estimators':[30, 35, 40, 45, 50, 55, 60],         \n",
    "    },\n",
    "#     GradientBoostingRegressor\n",
    "    {\n",
    "        'loss':['ls','lad','huber', 'quantile'],\n",
    "        'learning_rate':[0.1, 0.01, 0.001], \n",
    "        'n_estimators':[100,200,300],\n",
    "        'max_depth':[1,2,3,4],\n",
    "        'min_samples_split':[0.1, 0.25, 0.75, 1.0], #(0, 1)\n",
    "        'min_weight_fraction_leaf':[0,0.25,0.5],  # [0, 0.5]  \n",
    "    },\n",
    "#     ExtraTreesRegressor\n",
    "    {\n",
    "        'n_estimators':[30, 35, 40, 45, 50, 55, 60], \n",
    "        'criterion':['mse', 'mae'],        \n",
    "    },\n",
    "#     KNeighborsClassifier\n",
    "    {\n",
    "        'n_neighbors':[5,6,7,8,9,10,11,12],\n",
    "        'weights':['uniform', 'distance'],\n",
    "        'leaf_size':[20,25,30,35,40],        \n",
    "    },\n",
    "#     LinearSVR\n",
    "    {\n",
    "        'loss':['epsilon_insensitive', 'squared_epsilon_insensitive']        \n",
    "    },\n",
    "#     SVR\n",
    "    {\n",
    "        'kernel':['rbf', 'sigmoid', 'linear', 'poly']\n",
    "        \n",
    "    },\n",
    "#     NuSVR\n",
    "    {\n",
    "        \n",
    "    },\n",
    "#     DecisionTreeClassifier\n",
    "    {\n",
    "        \n",
    "    },\n",
    "#     DecisionTreeRegressor\n",
    "    {\n",
    "        \n",
    "    },\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLA_Hyperparameter = pd.DataFrame(columns=['Name', 'Train_Score', 'Test_Score', 'Time', 'Parameters'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "starting: AdaBoostClassifier\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\farooq\\desktop\\kaggle_projects\\lib\\site-packages\\sklearn\\model_selection\\_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-186-d5f2d200129f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mstart\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mtune_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_selection\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mparams\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m     \u001b[0mtune_model\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrain_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m     \u001b[0mend\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m     \u001b[0mtime_taken\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mend\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\farooq\\desktop\\kaggle_projects\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[0;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[1;32m--> 639\u001b[1;33m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[0;32m    640\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    641\u001b[0m         \u001b[1;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\farooq\\desktop\\kaggle_projects\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    777\u001b[0m             \u001b[1;31m# was dispatched. In particular this covers the edge\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[1;31m# case of Parallel used with an exhausted iterator.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\farooq\\desktop\\kaggle_projects\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    623\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    624\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 625\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    626\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\farooq\\desktop\\kaggle_projects\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    586\u001b[0m         \u001b[0mdispatch_timestamp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    587\u001b[0m         \u001b[0mcb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBatchCompletionCallBack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdispatch_timestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 588\u001b[1;33m         \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    589\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    590\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\farooq\\desktop\\kaggle_projects\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    109\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    110\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 111\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    112\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    113\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\farooq\\desktop\\kaggle_projects\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    330\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 332\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    333\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    334\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\farooq\\desktop\\kaggle_projects\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\farooq\\desktop\\kaggle_projects\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    129\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    130\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 131\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    132\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    133\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\farooq\\desktop\\kaggle_projects\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, error_score)\u001b[0m\n\u001b[0;32m    490\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mreturn_train_score\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    491\u001b[0m             train_scores = _score(estimator, X_train, y_train, scorer,\n\u001b[1;32m--> 492\u001b[1;33m                                   is_multimetric)\n\u001b[0m\u001b[0;32m    493\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    494\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mverbose\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\farooq\\desktop\\kaggle_projects\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_score\u001b[1;34m(estimator, X_test, y_test, scorer, is_multimetric)\u001b[0m\n\u001b[0;32m    521\u001b[0m     \"\"\"\n\u001b[0;32m    522\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mis_multimetric\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 523\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0m_multimetric_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    524\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    525\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0my_test\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\farooq\\desktop\\kaggle_projects\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_multimetric_score\u001b[1;34m(estimator, X_test, y_test, scorers)\u001b[0m\n\u001b[0;32m    551\u001b[0m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 553\u001b[1;33m             \u001b[0mscore\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mscorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    554\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    555\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'item'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\farooq\\desktop\\kaggle_projects\\lib\\site-packages\\sklearn\\metrics\\scorer.py\u001b[0m in \u001b[0;36m_passthrough_scorer\u001b[1;34m(estimator, *args, **kwargs)\u001b[0m\n\u001b[0;32m    242\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_passthrough_scorer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    243\u001b[0m     \u001b[1;34m\"\"\"Function that wraps estimator.score\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 244\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    245\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    246\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\farooq\\desktop\\kaggle_projects\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    347\u001b[0m         \"\"\"\n\u001b[0;32m    348\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 349\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    350\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\farooq\\desktop\\kaggle_projects\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    600\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mclasses\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m         \"\"\"\n\u001b[1;32m--> 602\u001b[1;33m         \u001b[0mpred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    603\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    604\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_classes_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\farooq\\desktop\\kaggle_projects\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py\u001b[0m in \u001b[0;36mdecision_function\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    668\u001b[0m             \u001b[1;31m# The weights are all 1. for SAMME.R\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m             pred = sum(_samme_proba(estimator, n_classes, X)\n\u001b[1;32m--> 670\u001b[1;33m                        for estimator in self.estimators_)\n\u001b[0m\u001b[0;32m    671\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m   \u001b[1;31m# self.algorithm == \"SAMME\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m             pred = sum((estimator.predict(X) == classes).T * w\n",
      "\u001b[1;32mc:\\users\\farooq\\desktop\\kaggle_projects\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    668\u001b[0m             \u001b[1;31m# The weights are all 1. for SAMME.R\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    669\u001b[0m             pred = sum(_samme_proba(estimator, n_classes, X)\n\u001b[1;32m--> 670\u001b[1;33m                        for estimator in self.estimators_)\n\u001b[0m\u001b[0;32m    671\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m   \u001b[1;31m# self.algorithm == \"SAMME\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    672\u001b[0m             pred = sum((estimator.predict(X) == classes).T * w\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "row_number = 0\n",
    "for alg, params in zip(MLA, gird_params):\n",
    "    alg_name = alg.__class__.__name__\n",
    "    print(\"starting:\", alg_name)\n",
    "    \n",
    "    start = time.time()\n",
    "    tune_model = model_selection.GridSearchCV(alg, param_grid=params)\n",
    "    tune_model.fit(train_X, train_y)\n",
    "    end = time.time()\n",
    "    time_taken = end - start \n",
    "    \n",
    "    train_score = tune_model.score(train_X, train_y)\n",
    "    test_score = tune_model.score(test_X, test_y)\n",
    "    \n",
    "    # add to pandas dataframe\n",
    "    MLA_Hyperparameter.loc[row_number] = [alg_name, train_score, test_score, time_taken, tune_model.best_params_]\n",
    "    row_number+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "MLA_Hyperparameter.sort_values(by=['Test_Score'], ascending=False, inplace=True)\n",
    "MLA_Hyperparameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLA_Hyperparameter.to_csv('./score/hyperparameters_mla_scores_20k.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ml_training(MLA, params=[]):\n",
    "    \n",
    "    row_number = 0\n",
    "    for alg, params in zip(MLA, gird_params):\n",
    "        alg_name = alg.__class__.__name__\n",
    "        print(\"starting:\", alg_name)\n",
    "\n",
    "        start = time.time()\n",
    "        tune_model = model_selection.GridSearchCV(alg, param_grid=params)\n",
    "        tune_model.fit(train_X, train_y)\n",
    "        end = time.time()\n",
    "        time_taken = end - start \n",
    "\n",
    "        train_score = tune_model.score(train_X, train_y)\n",
    "        test_score = tune_model.score(test_X, test_y)\n",
    "\n",
    "        # add to pandas dataframe\n",
    "        MLA_Hyperparameter.loc[row_number] = [alg_name, train_score, test_score, time_taken, tune_model.best_params_]\n",
    "        row_number+=1\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
