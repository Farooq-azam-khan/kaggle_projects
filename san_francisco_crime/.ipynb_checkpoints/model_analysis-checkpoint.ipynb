{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# System modules\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "\n",
    "# Data Analysis and Modeling modules\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "\n",
    "# modeling algorithms\n",
    "from sklearn import (svm, \n",
    "                     tree, \n",
    "                     linear_model, \n",
    "                     neighbors, \n",
    "                     naive_bayes, \n",
    "                     ensemble, \n",
    "                     discriminant_analysis, \n",
    "                     gaussian_process)\n",
    "\n",
    "# import xgboost\n",
    "\n",
    "# helper methods\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn import feature_selection\n",
    "from sklearn import model_selection\n",
    "from sklearn import metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_raw = pd.read_csv('./data/processed_train_data.csv')\n",
    "test_data = pd.read_csv('./data/processed_test_data.csv')\n",
    "# train_data_raw.head()\n",
    "# Create a copy of the data to work on\n",
    "train_data = train_data_raw.copy(deep=True)\n",
    "data_cleaner = [train_data, test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 878049 entries, 0 to 878048\n",
      "Data columns (total 38 columns):\n",
      "Unnamed: 0        878049 non-null int64\n",
      "Dates             878049 non-null object\n",
      "Category          878049 non-null object\n",
      "Descript          878049 non-null object\n",
      "DayOfWeek         878049 non-null object\n",
      "PdDistrict        878049 non-null object\n",
      "Resolution        878049 non-null object\n",
      "Address           878049 non-null object\n",
      "X                 878049 non-null float64\n",
      "Y                 878049 non-null float64\n",
      "Datetime_Dates    878049 non-null object\n",
      "Workhour          878049 non-null int64\n",
      "isHoliday         878049 non-null int64\n",
      "Month             878049 non-null int64\n",
      "isSummer          878049 non-null int64\n",
      "isWinter          878049 non-null int64\n",
      "isAutumn          878049 non-null int64\n",
      "isSpring          878049 non-null int64\n",
      "BAYVIEW           878049 non-null int64\n",
      "CENTRAL           878049 non-null int64\n",
      "INGLESIDE         878049 non-null int64\n",
      "MISSION           878049 non-null int64\n",
      "NORTHERN          878049 non-null int64\n",
      "PARK              878049 non-null int64\n",
      "RICHMOND          878049 non-null int64\n",
      "SOUTHERN          878049 non-null int64\n",
      "TARAVAL           878049 non-null int64\n",
      "TENDERLOIN        878049 non-null int64\n",
      "Friday            878049 non-null int64\n",
      "Monday            878049 non-null int64\n",
      "Saturday          878049 non-null int64\n",
      "Sunday            878049 non-null int64\n",
      "Thursday          878049 non-null int64\n",
      "Tuesday           878049 non-null int64\n",
      "Wednesday         878049 non-null int64\n",
      "Year              878049 non-null int64\n",
      "Day               878049 non-null int64\n",
      "Hour              878049 non-null int64\n",
      "dtypes: float64(2), int64(28), object(8)\n",
      "memory usage: 254.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# print(train_data[train_data['Category'].unique().tolist()].head(5))\n",
    "print(train_data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = pd.concat([train_data, pd.get_dummies(train_data['Category'])], axis=1)\n",
    "data_cleaner = [train_data, test_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "label = LabelEncoder()\n",
    "train_data['category_Code'] = label.fit_transform(train_data['Category'])\n",
    "train_data['category_Code'] = train_data['category_Code'].map(lambda x: x+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "print(np.max(train_data['category_Code'].unique()))\n",
    "print(np.min(train_data['category_Code'].unique()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['Address_Code'] = label.fit_transform(train_data['Address'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['NORTHERN' 'PARK' 'INGLESIDE' 'BAYVIEW' 'RICHMOND' 'CENTRAL' 'TARAVAL'\n",
      " 'TENDERLOIN' 'MISSION' 'SOUTHERN' 'isSummer' 'isAutumn' 'isWinter'\n",
      " 'isSpring' 'Workhour' 'isHoliday' 'Hour' 'Year' 'Month' 'Day' 'X' 'Y'\n",
      " 'Address_Code' 'Wednesday' 'Tuesday' 'Monday' 'Sunday' 'Saturday'\n",
      " 'Friday' 'Thursday']\n"
     ]
    }
   ],
   "source": [
    "features = np.append(train_data['PdDistrict'].unique(), ['isSummer', 'isAutumn', 'isWinter', 'isSpring'])\n",
    "features = np.append(features, ['Workhour', 'isHoliday', 'Hour', 'Year', 'Month', 'Day', 'X', 'Y', 'Address_Code'])\n",
    "features = np.append(features, train_data['DayOfWeek'].unique())\n",
    "print(features)\n",
    "\n",
    "targets_dummy = train_data['Category'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "print(len(features))\n",
    "print(len(targets_dummy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_train_data = train_data.sample(100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = model_selection.train_test_split(small_train_data[features], \n",
    "                                                                    small_train_data['category_Code'], \n",
    "                                                                    random_state=0)\n",
    "train_X_dummy, test_X_dummy, train_y_dummy, test_y_dummy = model_selection.train_test_split(small_train_data[features], \n",
    "                                                                   small_train_data[targets_dummy], \n",
    "                                                                   random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total shape: (100000, 79)\n",
      "Train shape: (75000, 30) (75000,)\n",
      "Test shape: (25000, 30) (25000,)\n"
     ]
    }
   ],
   "source": [
    "print('Total shape:', small_train_data.shape)\n",
    "print('Train shape:', train_X.shape, train_y.shape)\n",
    "print('Test shape:', test_X.shape, test_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        NORTHERN  PARK  INGLESIDE  BAYVIEW  RICHMOND  CENTRAL  TARAVAL  \\\n",
      "36984          0     0          0        0         0        0        0   \n",
      "10221          0     0          0        0         0        1        0   \n",
      "637200         0     0          1        0         0        0        0   \n",
      "220119         0     0          0        0         0        0        0   \n",
      "822156         0     0          1        0         0        0        0   \n",
      "\n",
      "        TENDERLOIN  MISSION  SOUTHERN    ...              X          Y  \\\n",
      "36984            1        0         0    ...    -122.409524  37.785760   \n",
      "10221            0        0         0    ...    -122.416793  37.796019   \n",
      "637200           0        0         0    ...    -122.409328  37.722801   \n",
      "220119           0        0         1    ...    -122.390136  37.789481   \n",
      "822156           0        0         0    ...    -122.414583  37.708936   \n",
      "\n",
      "        Address_Code  Wednesday  Tuesday  Monday  Sunday  Saturday  Friday  \\\n",
      "36984           5967          0        0       0       0         0       1   \n",
      "10221           4553          0        0       0       0         1       0   \n",
      "637200          2749          0        0       1       0         0       0   \n",
      "220119          8777          0        0       0       0         1       0   \n",
      "822156         10838          1        0       0       0         0       0   \n",
      "\n",
      "        Thursday  \n",
      "36984          0  \n",
      "10221          0  \n",
      "637200         0  \n",
      "220119         0  \n",
      "822156         0  \n",
      "\n",
      "[5 rows x 30 columns]\n"
     ]
    }
   ],
   "source": [
    "print(train_X.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "MLA = [\n",
    "    #Ensemble Methods\n",
    "    ensemble.AdaBoostClassifier(),\n",
    "    ensemble.BaggingClassifier(),\n",
    "    ensemble.ExtraTreesClassifier(),\n",
    "#     ensemble.GradientBoostingClassifier(),\n",
    "    ensemble.RandomForestClassifier(),\n",
    "\n",
    "    #Gaussian Processes\n",
    "#     gaussian_process.GaussianProcessClassifier(),\n",
    "    \n",
    "    #GLM\n",
    "#     linear_model.LogisticRegressionCV(),\n",
    "    linear_model.PassiveAggressiveClassifier(),\n",
    "    linear_model.RidgeClassifierCV(),\n",
    "    linear_model.SGDClassifier(),\n",
    "    linear_model.Perceptron(),\n",
    "    \n",
    "    #Navies Bayes\n",
    "    naive_bayes.BernoulliNB(),\n",
    "    naive_bayes.GaussianNB(),\n",
    "    \n",
    "    #Nearest Neighbor\n",
    "    neighbors.KNeighborsClassifier(),\n",
    "    \n",
    "    #SVM\n",
    "#     svm.SVC(probability=True),\n",
    "#     svm.NuSVC(probability=True),\n",
    "#     svm.LinearSVC(),\n",
    "    \n",
    "    #Trees    \n",
    "    tree.DecisionTreeClassifier(),\n",
    "    tree.ExtraTreeClassifier(),\n",
    "    \n",
    "    #Discriminant Analysis\n",
    "    discriminant_analysis.LinearDiscriminantAnalysis(),\n",
    "#     discriminant_analysis.QuadraticDiscriminantAnalysis(),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create table to compare MLA metrics\n",
    "MLA_columns = ['MLA Name', 'MLA Parameters','MLA Train Accuracy Mean', 'MLA Test Accuracy Mean'] #, 'MLA Test Accuracy 3*STD' ,'MLA Time']\n",
    "MLA_compare = pd.DataFrame(columns = MLA_columns)\n",
    "# cv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 0 ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ALG: AdaBoostClassifier\n",
      "done fitting\n",
      "train acc: 0.21114666666666668\n",
      "test acc: 0.21292\n",
      "--------------------------------------------------\n",
      "ALG: BaggingClassifier\n",
      "done fitting\n",
      "train acc: 0.9692933333333333\n",
      "test acc: 0.22768\n",
      "--------------------------------------------------\n",
      "ALG: ExtraTreesClassifier\n",
      "done fitting\n",
      "train acc: 0.9822533333333333\n",
      "test acc: 0.1966\n",
      "--------------------------------------------------\n",
      "ALG: RandomForestClassifier\n",
      "done fitting\n",
      "train acc: 0.9709066666666667\n",
      "test acc: 0.2186\n",
      "--------------------------------------------------\n",
      "ALG: PassiveAggressiveClassifier\n",
      "done fitting\n",
      "train acc: 0.10825333333333333\n",
      "test acc: 0.10924\n",
      "--------------------------------------------------\n",
      "ALG: RidgeClassifierCV\n",
      "done fitting\n",
      "train acc: 0.2294\n",
      "test acc: 0.2306\n",
      "--------------------------------------------------\n",
      "ALG: SGDClassifier\n",
      "done fitting\n",
      "train acc: 0.19312\n",
      "test acc: 0.19652\n",
      "--------------------------------------------------\n",
      "ALG: Perceptron\n",
      "done fitting\n",
      "train acc: 0.019413333333333335\n",
      "test acc: 0.0178\n",
      "--------------------------------------------------\n",
      "ALG: BernoulliNB\n",
      "done fitting\n",
      "train acc: 0.22177333333333332\n",
      "test acc: 0.2224\n",
      "--------------------------------------------------\n",
      "ALG: GaussianNB\n",
      "done fitting\n",
      "train acc: 0.12782666666666667\n",
      "test acc: 0.12896\n",
      "--------------------------------------------------\n",
      "ALG: KNeighborsClassifier\n",
      "done fitting\n",
      "train acc: 0.40641333333333335\n",
      "test acc: 0.18912\n",
      "--------------------------------------------------\n",
      "ALG: DecisionTreeClassifier\n",
      "done fitting\n",
      "train acc: 0.9822533333333333\n",
      "test acc: 0.17352\n",
      "--------------------------------------------------\n",
      "ALG: ExtraTreeClassifier\n",
      "done fitting\n",
      "train acc: 0.9822533333333333\n",
      "test acc: 0.14724\n",
      "--------------------------------------------------\n",
      "ALG: LinearDiscriminantAnalysis\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\farooq\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\discriminant_analysis.py:455: UserWarning: The priors do not sum to 1. Renormalizing\n",
      "  UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done fitting\n",
      "train acc: 0.23110666666666665\n",
      "test acc: 0.23284\n",
      "--------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\farooq\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\discriminant_analysis.py:387: UserWarning: Variables are collinear.\n",
      "  warnings.warn(\"Variables are collinear.\")\n"
     ]
    }
   ],
   "source": [
    "row_index = 0\n",
    "for alg in MLA:\n",
    "    #set name and parameters\n",
    "    MLA_name = alg.__class__.__name__\n",
    "    print(\"ALG:\", MLA_name)\n",
    "    MLA_compare.loc[row_index, 'MLA Name'] = MLA_name\n",
    "    MLA_compare.loc[row_index, 'MLA Parameters'] = str(alg.get_params())\n",
    "    \n",
    "    alg.fit(train_X, train_y)\n",
    "    print(\"done fitting\")\n",
    "    \n",
    "    MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'] = alg.score(train_X, train_y)\n",
    "    MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'] = alg.score(test_X, test_y)\n",
    "    \n",
    "    print(\"train acc:\", MLA_compare.loc[row_index, 'MLA Train Accuracy Mean'])\n",
    "    print(\"test acc:\", MLA_compare.loc[row_index, 'MLA Test Accuracy Mean'])\n",
    "    \n",
    "    row_index+=1\n",
    "    print(\"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                         MLA Name  \\\n",
      "13     LinearDiscriminantAnalysis   \n",
      "5               RidgeClassifierCV   \n",
      "1               BaggingClassifier   \n",
      "8                     BernoulliNB   \n",
      "3          RandomForestClassifier   \n",
      "0              AdaBoostClassifier   \n",
      "2            ExtraTreesClassifier   \n",
      "6                   SGDClassifier   \n",
      "10           KNeighborsClassifier   \n",
      "11         DecisionTreeClassifier   \n",
      "12            ExtraTreeClassifier   \n",
      "9                      GaussianNB   \n",
      "4     PassiveAggressiveClassifier   \n",
      "7                      Perceptron   \n",
      "14  QuadraticDiscriminantAnalysis   \n",
      "\n",
      "                                       MLA Parameters MLA Train Accuracy Mean  \\\n",
      "13  {'n_components': None, 'priors': None, 'shrink...                0.231107   \n",
      "5   {'alphas': (0.1, 1.0, 10.0), 'class_weight': N...                  0.2294   \n",
      "1   {'base_estimator': None, 'bootstrap': True, 'b...                0.969293   \n",
      "8   {'alpha': 1.0, 'binarize': 0.0, 'class_prior':...                0.221773   \n",
      "3   {'bootstrap': True, 'class_weight': None, 'cri...                0.970907   \n",
      "0   {'algorithm': 'SAMME.R', 'base_estimator': Non...                0.211147   \n",
      "2   {'bootstrap': False, 'class_weight': None, 'cr...                0.982253   \n",
      "6   {'alpha': 0.0001, 'average': False, 'class_wei...                 0.19312   \n",
      "10  {'algorithm': 'auto', 'leaf_size': 30, 'metric...                0.406413   \n",
      "11  {'class_weight': None, 'criterion': 'gini', 'm...                0.982253   \n",
      "12  {'class_weight': None, 'criterion': 'gini', 'm...                0.982253   \n",
      "9                                    {'priors': None}                0.127827   \n",
      "4   {'C': 1.0, 'class_weight': None, 'fit_intercep...                0.108253   \n",
      "7   {'alpha': 0.0001, 'class_weight': None, 'eta0'...               0.0194133   \n",
      "14  {'priors': None, 'reg_param': 0.0, 'store_cova...                     NaN   \n",
      "\n",
      "   MLA Test Accuracy Mean  \n",
      "13                0.23284  \n",
      "5                  0.2306  \n",
      "1                 0.22768  \n",
      "8                  0.2224  \n",
      "3                  0.2186  \n",
      "0                 0.21292  \n",
      "2                  0.1966  \n",
      "6                 0.19652  \n",
      "10                0.18912  \n",
      "11                0.17352  \n",
      "12                0.14724  \n",
      "9                 0.12896  \n",
      "4                 0.10924  \n",
      "7                  0.0178  \n",
      "14                    NaN  \n"
     ]
    }
   ],
   "source": [
    "MLA_compare.sort_values(by = ['MLA Test Accuracy Mean'], ascending = False, inplace = True)\n",
    "print(MLA_compare)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_split = model_selection.ShuffleSplit(n_splits = 10, test_size = .3, train_size = .6, random_state = 0 )\n",
    "param_grid = {'criterion': ['gini', 'entropy'],  #scoring methodology; two supported formulas for calculating information gain - default is gini\n",
    "              #'splitter': ['best', 'random'], #splitting methodology; two supported strategies - default is best\n",
    "              'max_depth': [2,4,6,8,10,None], #max depth tree can grow; default is none\n",
    "              #'min_samples_split': [2,5,10,.03,.05], #minimum subset size BEFORE new split (fraction is % of total); default is 2\n",
    "              #'min_samples_leaf': [1,5,10,.03,.05], #minimum subset size AFTER new split split (fraction is % of total); default is 1\n",
    "              #'max_features': [None, 'auto'], #max features to consider when performing split; default none or all\n",
    "              'random_state': [0] #seed or control random number generator: https://www.quora.com/What-is-seed-in-random-number-generation\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\farooq\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\sklearn\\model_selection\\_split.py:581: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of groups for any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score='raise',\n",
       "       estimator=RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
       "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "            n_estimators=10, n_jobs=1, oob_score=False, random_state=None,\n",
       "            verbose=0, warm_start=False),\n",
       "       fit_params={}, iid=True, n_jobs=1,\n",
       "       param_grid={'criterion': ['gini', 'entropy'], 'max_depth': [2, 4, 6, 8, 10, None], 'random_state': [0]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=0)"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tune_model = model_selection.GridSearchCV(ensemble.RandomForestClassifier(), param_grid=param_grid)\n",
    "tune_model.fit(train_X, train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Score: (after) 0.29\n",
      "Testing Score: (after) 0.25\n"
     ]
    }
   ],
   "source": [
    "print(\"Training Score: (after) {:.2f}\".format(tune_model.score(train_X, train_y)))\n",
    "print(\"Testing Score: (after) {:.2f}\".format(tune_model.score(test_X, test_y)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Log Loss / score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tune_model.predict_proba(train_data[features])\n",
    "\n",
    "# print(\"Train Accuracy:\", model3.score(train_X, train_y))\n",
    "# print(\"Test Accuracy:\", model3.score(test_X, test_y))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.5078220703707275\n"
     ]
    }
   ],
   "source": [
    "print(metrics.log_loss(train_data['category_Code'],predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
