{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "# haandle data\n",
    "import json\n",
    "import operator\n",
    "import collections\n",
    "from sklearn import svm\n",
    "from sklearn.model_selection  import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load json file\n",
    "with open('./data/train.json') as data_file:\n",
    "    train_data = json.load(data_file)\n",
    "\n",
    "with open('./data/test.json') as data_file:\n",
    "    test_data = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all ingredients in all dishes\n",
    "def get_ingredients(json):\n",
    "    raw_ingredients = list()\n",
    "    for dish in json:\n",
    "        for ingredient in dish['ingredients']:\n",
    "            raw_ingredients.append(ingredient.strip())\n",
    "    return raw_ingredients\n",
    "raw_ingredients = list(set(get_ingredients(train_data)))\n",
    "train_ingredients = collections.Counter(get_ingredients(train_data))\n",
    "# get all cusines\n",
    "\n",
    "def get_cuisine(json):\n",
    "    raw_cuisines = list()\n",
    "    for dish in json:\n",
    "        raw_cuisines.append(dish['cuisine'].strip())\n",
    "    return raw_cuisines\n",
    "raw_cuisines = list(set(get_cuisine(train_data)))\n",
    "train_cuisines =  collections.Counter(get_cuisine(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(train_data[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of ingredients: 6714\n",
      "number of trainning dishes: 39774\n",
      "number of testing dishes: 9944\n"
     ]
    }
   ],
   "source": [
    "number_of_ingredients = len(train_ingredients)\n",
    "print(\"number of ingredients:\", number_of_ingredients)\n",
    "number_of_train_dishes = len(train_data)\n",
    "print(\"number of trainning dishes:\", number_of_train_dishes )\n",
    "number_of_test_dishes = len(test_data)\n",
    "print(\"number of testing dishes:\", number_of_test_dishes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_matrix = np.zeros((number_of_train_dishes, number_of_ingredients))\n",
    "for row, dish in enumerate(train_data):\n",
    "    ingredients = dish['ingredients']\n",
    "    for ingredient in ingredients:\n",
    "        col = raw_ingredients.index(ingredient)\n",
    "        model_matrix[row, col] = 1\n",
    "        \n",
    "def create_model_matrix(json):\n",
    "    data_size = len(json)\n",
    "    model_matrix = np.zeros((data_size, number_of_ingredients))\n",
    "    for row, dish in enumerate(json):\n",
    "        ingredients = dish['ingredients']\n",
    "        for ingredient in ingredients:\n",
    "            if ingredient in raw_ingredients:\n",
    "                col = raw_ingredients.index(ingredient)\n",
    "                model_matrix[row, col] = 1\n",
    "    return model_matrix\n",
    "\n",
    "test_model_matrix = create_model_matrix(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features: 6714\n",
      "39774\n",
      "data: None\n"
     ]
    }
   ],
   "source": [
    "print('features:', len(model_matrix[0]))\n",
    "print('data:', print(len(model_matrix)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels: ['mexican', 'british', 'brazilian', 'greek', 'jamaican', 'southern_us', 'korean', 'spanish', 'indian', 'russian', 'chinese', 'cajun_creole', 'irish', 'vietnamese', 'thai', 'moroccan', 'japanese', 'filipino', 'italian', 'french'] : 20\n",
      "labels data: 39774\n"
     ]
    }
   ],
   "source": [
    "print('labels:',  raw_cuisines, \":\", len(raw_cuisines))\n",
    "print('labels data:',  len([raw_cuisines.index(dish['cuisine']) for dish in train_data]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "features = model_matrix\n",
    "\n",
    "\n",
    "from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\n",
    "# make label into onehot array\n",
    "raw_target = [raw_cuisines.index(dish['cuisine']) for dish in train_data]\n",
    "one_hot_label = to_categorical(raw_target)\n",
    "target = one_hot_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X, test_X, train_y, test_y = train_test_split(features, target, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "39774\n"
     ]
    }
   ],
   "source": [
    "print(len(one_hot_label[0]))\n",
    "print(len(one_hot_label))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. ... 0. 0. 0.]\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'greek'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(train_X[0])\n",
    "print(one_hot_label[0])\n",
    "raw_cuisines[np.argmax(one_hot_label)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "clf = KNeighborsRegressor()\n",
    "clf.fit(train_X, train_y)\n",
    "print(clf.score(test_X, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define model \n",
    "model = Sequential()\n",
    "model.add(Dense(300, input_shape=(6714,)))\n",
    "model.add(Dense(300, activation=tf.nn.relu))\n",
    "model.add(Dense(300, activation=tf.nn.relu))\n",
    "model.add(Dense(300, activation=tf.nn.relu))\n",
    "model.add(Dense(300, activation=tf.nn.relu))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(300, activation=tf.nn.relu))\n",
    "model.add(Dense(300, activation=tf.nn.relu))\n",
    "model.add(Dense(20, activation=tf.nn.softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', \n",
    "             loss = 'categorical_crossentropy', \n",
    "             metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 29830 samples, validate on 9944 samples\n",
      "Epoch 1/20\n",
      "29830/29830 [==============================] - 19s 634us/step - loss: 1.3796 - acc: 0.5889 - val_loss: 1.0108 - val_acc: 0.7039\n",
      "Epoch 2/20\n",
      "29830/29830 [==============================] - 19s 624us/step - loss: 0.8166 - acc: 0.7567 - val_loss: 0.9232 - val_acc: 0.7374\n",
      "Epoch 3/20\n",
      "29830/29830 [==============================] - 19s 623us/step - loss: 0.6224 - acc: 0.8162 - val_loss: 0.8851 - val_acc: 0.7543\n",
      "Epoch 4/20\n",
      "29830/29830 [==============================] - 20s 668us/step - loss: 0.4940 - acc: 0.8545 - val_loss: 0.9142 - val_acc: 0.7566\n",
      "Epoch 5/20\n",
      "29830/29830 [==============================] - 19s 652us/step - loss: 0.3986 - acc: 0.8812 - val_loss: 0.9779 - val_acc: 0.7555\n",
      "Epoch 6/20\n",
      "29830/29830 [==============================] - 18s 593us/step - loss: 0.3221 - acc: 0.9031 - val_loss: 1.0346 - val_acc: 0.7603\n",
      "Epoch 7/20\n",
      "29830/29830 [==============================] - 18s 591us/step - loss: 0.2667 - acc: 0.9215 - val_loss: 1.1523 - val_acc: 0.7574\n",
      "Epoch 8/20\n",
      "29830/29830 [==============================] - 18s 589us/step - loss: 0.2209 - acc: 0.9348 - val_loss: 1.2359 - val_acc: 0.7403\n",
      "Epoch 9/20\n",
      "29830/29830 [==============================] - 18s 592us/step - loss: 0.1933 - acc: 0.9432 - val_loss: 1.2967 - val_acc: 0.7446\n",
      "Epoch 10/20\n",
      "29830/29830 [==============================] - 18s 588us/step - loss: 0.1732 - acc: 0.9492 - val_loss: 1.3600 - val_acc: 0.7540\n",
      "Epoch 11/20\n",
      "29830/29830 [==============================] - 18s 604us/step - loss: 0.1383 - acc: 0.9594 - val_loss: 1.4015 - val_acc: 0.7537\n",
      "Epoch 12/20\n",
      "29830/29830 [==============================] - 18s 615us/step - loss: 0.1280 - acc: 0.9631 - val_loss: 1.4541 - val_acc: 0.7395\n",
      "Epoch 13/20\n",
      "29830/29830 [==============================] - 18s 616us/step - loss: 0.1105 - acc: 0.9685 - val_loss: 1.4122 - val_acc: 0.7424\n",
      "Epoch 14/20\n",
      "29830/29830 [==============================] - 19s 635us/step - loss: 0.1020 - acc: 0.9697 - val_loss: 1.6117 - val_acc: 0.7452\n",
      "Epoch 15/20\n",
      "29830/29830 [==============================] - 19s 623us/step - loss: 0.0879 - acc: 0.9742 - val_loss: 1.5248 - val_acc: 0.7449\n",
      "Epoch 16/20\n",
      "29830/29830 [==============================] - 18s 614us/step - loss: 0.0689 - acc: 0.9799 - val_loss: 1.6448 - val_acc: 0.7498\n",
      "Epoch 17/20\n",
      "29830/29830 [==============================] - 18s 614us/step - loss: 0.0784 - acc: 0.9784 - val_loss: 1.5379 - val_acc: 0.7486\n",
      "Epoch 18/20\n",
      "29830/29830 [==============================] - 18s 619us/step - loss: 0.0671 - acc: 0.9817 - val_loss: 1.7677 - val_acc: 0.7410\n",
      "Epoch 19/20\n",
      "29830/29830 [==============================] - 19s 625us/step - loss: 0.0625 - acc: 0.9831 - val_loss: 1.7634 - val_acc: 0.7452\n",
      "Epoch 20/20\n",
      "29830/29830 [==============================] - 19s 630us/step - loss: 0.0563 - acc: 0.9847 - val_loss: 1.7480 - val_acc: 0.7487\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x14e80853208>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batchsize = 100\n",
    "epochs = 20\n",
    "model.fit(train_X, train_y, epochs=epochs, batch_size=batchsize, validation_data=(test_X, test_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('./whats_cooking_ingredients_as_features.model')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(test_model_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cuisine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>35203</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17600</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35200</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17602</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17605</td>\n",
       "      <td>italian</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      id  cuisine\n",
       "0  35203  italian\n",
       "1  17600  italian\n",
       "2  35200  italian\n",
       "3  17602  italian\n",
       "4  17605  italian"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss = pd.read_csv('./data/sample_submission.csv')\n",
    "ss.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "written_preds = [raw_cuisines[np.argmax(pred)] for pred in predictions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss['cuisine'] = written_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss.to_csv('./data/submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
